# -*- coding: utf-8 -*-
"""4A_Vector_Add_Final.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1xmliFmZtlrdHnSpk18TkyiRR7qoAKyDz
"""

!pip install git+https://github.com/andreinechaev/nvcc4jupyter.git

!nvcc --version

pip install nvcc4jupyter

# Commented out IPython magic to ensure Python compatibility.
# %load_ext nvcc4jupyter



# Commented out IPython magic to ensure Python compatibility.
# %%cuda
# 
# #include <stdio.h>
# 
# #define HANDLE_ERROR( err ) ( HandleError( err, __FILE__, __LINE__ ) )
# 
# static void HandleError( cudaError_t err, const char *file, int line )
# {
#     if (err != cudaSuccess)
#       {
#         printf( "%s in %s at line %d\n", cudaGetErrorString( err ),
#                 file, line );
#         exit( EXIT_FAILURE );
#     }
# }
# 
# const int N = 1000000; // 1 million
# 
# __global__ void Vector_Addition_CUDA(const int *dev_a, const int *dev_b, int *dev_c, int n)
# {
#     int tid = blockIdx.x * blockDim.x + threadIdx.x;
# 
#     if (tid < n)
#         dev_c[tid] = dev_a[tid] + dev_b[tid];
# }
# 
# int main(void)
# {
#     int *Host_a, *Host_b, *Host_c;
#     int *dev_a, *dev_b, *dev_c;
# 
#     // Allocate memory for host arrays
#     Host_a = (int*)malloc(N * sizeof(int));
#     Host_b = (int*)malloc(N * sizeof(int));
#     Host_c = (int*)malloc(N * sizeof(int));
# 
#     // Initialize host arrays
#     for (int i = 0; i < N; i++)
#     {
#         Host_a[i] = i;
#         Host_b[i] = i * i;
#     }
# 
#     // Allocate memory on device
#     HANDLE_ERROR(cudaMalloc((void **)&dev_a, N * sizeof(int)));
#     HANDLE_ERROR(cudaMalloc((void **)&dev_b, N * sizeof(int)));
#     HANDLE_ERROR(cudaMalloc((void **)&dev_c, N * sizeof(int)));
# 
#     // Copy host arrays to device
#     HANDLE_ERROR(cudaMemcpy(dev_a, Host_a, N * sizeof(int), cudaMemcpyHostToDevice));
#     HANDLE_ERROR(cudaMemcpy(dev_b, Host_b, N * sizeof(int), cudaMemcpyHostToDevice));
# 
#     // Calculate grid size
#     int threads_per_block = 256;
#     int num_blocks = (N + threads_per_block - 1) / threads_per_block;
# 
#     // Start timer
#     cudaEvent_t start, stop;
#     float cuda_elapsed_time_ms;
#     cudaEventCreate(&start);
#     cudaEventCreate(&stop);
#     cudaEventRecord(start, 0);
# 
#     // Launch kernel
#     Vector_Addition_CUDA<<<num_blocks, threads_per_block>>>(dev_a, dev_b, dev_c, N);
# 
#     // Stop timer
#     cudaEventRecord(stop, 0);
#     cudaEventSynchronize(stop);
#     cudaEventElapsedTime(&cuda_elapsed_time_ms, start, stop);
# 
#     // Copy result back to host
#     HANDLE_ERROR(cudaMemcpy(Host_c, dev_c, N * sizeof(int), cudaMemcpyDeviceToHost));
#       // Print result
#     for (int i = 0; i < N; i++)
#         printf("%d + %d = %d\n", Host_a[i], Host_b[i], Host_c[i]);
# 
#     // Print elapsed time
#     printf("Time elapsed on CUDA Vector addition for %d size input : %f ms.\n\n", N, cuda_elapsed_time_ms);
# 
#     // Free device memory
#     cudaFree(dev_a);
#     cudaFree(dev_b);
#     cudaFree(dev_c);
# 
#     // Free host memory
#     free(Host_a);
#     free(Host_b);
#     free(Host_c);
# 
#     return 0;
# }
#